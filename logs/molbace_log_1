[*] Run ID 1: seed=1, split_index=0
    Starting now: 2025-05-11 00:33:13.842598
[*] Loaded dataset 'ogbg-molbace' from 'OGB':
  Data(num_nodes=51577, edge_index=[2, 111536], edge_attr=[111536, 3], x=[51577, 9], y=[1513, 1])
  undirected: True
  num graphs: 1513
  avg num_nodes/graph: 34
  num node features: 9
  num edge features: 3
  num tasks: 1
  num classes: 2
Precomputing Positional Encoding statistics: ['RRWP'] for all graphs...
  ...estimated to be undirected: True
Done! Took 00:00:02.35
GraphGymModule(
  (model): GritTransformer(
    (encoder): FeatureEncoder(
      (node_encoder): AtomEncoder(
        (atom_embedding_list): ModuleList(
          (0): Embedding(119, 100)
          (1): Embedding(5, 100)
          (2-3): 2 x Embedding(12, 100)
          (4): Embedding(10, 100)
          (5-6): 2 x Embedding(6, 100)
          (7-8): 2 x Embedding(2, 100)
        )
      )
      (node_encoder_bn): BatchNorm1dNode(
        (bn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (edge_encoder): BondEncoder(
        (bond_embedding_list): ModuleList(
          (0): Embedding(5, 100)
          (1): Embedding(6, 100)
          (2): Embedding(2, 100)
        )
      )
      (edge_encoder_bn): BatchNorm1dNode(
        (bn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (rrwp_abs_encoder): RRWPLinearNodeEncoder(
      (fc): Linear(in_features=21, out_features=100, bias=False)
    )
    (rrwp_rel_encoder): RRWPLinearEdgeEncoder(pad_to_full_graph=True,fill_value=0.0,Linear(in_features=21, out_features=100, bias=False))
    (pre_mp): GeneralMultiLayer(
      (Layer_0): GeneralLayer(
        (layer): Linear(
          (model): Linear(100, 100, bias=False)
        )
        (post_layer): Sequential(
          (0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): PReLU(num_parameters=1)
        )
      )
    )
    (layers): Sequential(
      (0): GritTransformerLayer(in_channels=100, out_channels=100, heads=3, residual=True)
      [GritTransformerLayer(
        (act): PReLU(num_parameters=1)
        (attention): MultiHeadAttentionLayerGritSparse(
          (dropout): Dropout(p=0.2, inplace=False)
          (Q): Linear(in_features=100, out_features=99, bias=True)
          (K): Linear(in_features=100, out_features=99, bias=False)
          (E): Linear(in_features=100, out_features=198, bias=True)
          (V): Linear(in_features=100, out_features=99, bias=False)
          (act): ReLU()
        )
        (O_h): Linear(in_features=99, out_features=100, bias=True)
        (O_e): Linear(in_features=99, out_features=100, bias=True)
        (batch_norm1_h): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (batch_norm1_e): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (FFN_h_layer1): Linear(in_features=100, out_features=200, bias=True)
        (FFN_h_layer2): Linear(in_features=200, out_features=100, bias=True)
        (batch_norm2_h): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )]
      (1): GritTransformerLayer(in_channels=100, out_channels=100, heads=3, residual=True)
      [GritTransformerLayer(
        (act): PReLU(num_parameters=1)
        (attention): MultiHeadAttentionLayerGritSparse(
          (dropout): Dropout(p=0.2, inplace=False)
          (Q): Linear(in_features=100, out_features=99, bias=True)
          (K): Linear(in_features=100, out_features=99, bias=False)
          (E): Linear(in_features=100, out_features=198, bias=True)
          (V): Linear(in_features=100, out_features=99, bias=False)
          (act): ReLU()
        )
        (O_h): Linear(in_features=99, out_features=100, bias=True)
        (O_e): Linear(in_features=99, out_features=100, bias=True)
        (batch_norm1_h): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (batch_norm1_e): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (FFN_h_layer1): Linear(in_features=100, out_features=200, bias=True)
        (FFN_h_layer2): Linear(in_features=200, out_features=100, bias=True)
        (batch_norm2_h): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )]
      (2): GritTransformerLayer(in_channels=100, out_channels=100, heads=3, residual=True)
      [GritTransformerLayer(
        (act): PReLU(num_parameters=1)
        (attention): MultiHeadAttentionLayerGritSparse(
          (dropout): Dropout(p=0.2, inplace=False)
          (Q): Linear(in_features=100, out_features=99, bias=True)
          (K): Linear(in_features=100, out_features=99, bias=False)
          (E): Linear(in_features=100, out_features=198, bias=True)
          (V): Linear(in_features=100, out_features=99, bias=False)
          (act): ReLU()
        )
        (O_h): Linear(in_features=99, out_features=100, bias=True)
        (O_e): Linear(in_features=99, out_features=100, bias=True)
        (batch_norm1_h): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (batch_norm1_e): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (FFN_h_layer1): Linear(in_features=100, out_features=200, bias=True)
        (FFN_h_layer2): Linear(in_features=200, out_features=100, bias=True)
        (batch_norm2_h): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )]
      (3): GritTransformerLayer(in_channels=100, out_channels=100, heads=3, residual=True)
      [GritTransformerLayer(
        (act): PReLU(num_parameters=1)
        (attention): MultiHeadAttentionLayerGritSparse(
          (dropout): Dropout(p=0.2, inplace=False)
          (Q): Linear(in_features=100, out_features=99, bias=True)
          (K): Linear(in_features=100, out_features=99, bias=False)
          (E): Linear(in_features=100, out_features=198, bias=True)
          (V): Linear(in_features=100, out_features=99, bias=False)
          (act): ReLU()
        )
        (O_h): Linear(in_features=99, out_features=100, bias=True)
        (O_e): Linear(in_features=99, out_features=100, bias=True)
        (batch_norm1_h): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (batch_norm1_e): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (FFN_h_layer1): Linear(in_features=100, out_features=200, bias=True)
        (FFN_h_layer2): Linear(in_features=200, out_features=100, bias=True)
        (batch_norm2_h): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )]
    )
    (post_mp): GNNGraphHead(
      (layer_post_mp): MLP(
        (model): Sequential(
          (0): Linear(
            (model): Linear(100, 1, bias=True)
          )
        )
      )
    )
  )
)
accelerator: cpu
benchmark: False
best_by_loss: False
bn:
  eps: 1e-05
  mom: 0.1
cfg_dest: config.yaml
cfg_file: configs/GRIT/molbace-GRIT-RRWP.yaml
custom_metrics: []
dataset:
  cache_load: False
  cache_save: False
  dir: ./datasets
  edge_dim: 128
  edge_encoder: True
  edge_encoder_bn: True
  edge_encoder_name: Bond
  edge_encoder_num_types: 0
  edge_message_ratio: 0.8
  edge_negative_sampling_ratio: 1.0
  edge_train_mode: all
  encoder: True
  encoder_bn: True
  encoder_dim: 128
  encoder_name: db
  format: OGB
  label_column: none
  label_table: none
  location: local
  name: ogbg-molbace
  node_encoder: True
  node_encoder_bn: True
  node_encoder_name: Atom
  node_encoder_num_types: 0
  pe_transform_on_the_fly: False
  remove_feature: False
  resample_disjoint: False
  resample_negative: False
  shuffle_split: True
  slic_compactness: 10
  split: [0.8, 0.1, 0.1]
  split_dir: ./splits
  split_index: 0
  split_mode: standard
  task: graph
  task_type: classification
  to_undirected: False
  transductive: False
  transform: none
  tu_simple: True
device: cpu
devices: 1
example_arg: example
example_group:
  example_arg: example
gnn:
  act: prelu
  agg: mean
  att_final_linear: False
  att_final_linear_bn: False
  att_heads: 1
  batchnorm: True
  clear_feature: True
  dim_edge: 100
  dim_inner: 100
  dropout: 0.0
  head: graph
  keep_edge: 0.5
  l2norm: True
  layer_type: generalconv
  layers_mp: 2
  layers_post_mp: 1
  layers_pre_mp: 1
  msg_direction: single
  normalize_adj: False
  residual: False
  self_msg: concat
  skip_every: 1
  stage_type: stack
gpu_mem: False
gt:
  attn:
    O_e: True
    act: relu
    clamp: 5.0
    deg_scaler: True
    edge_enhance: True
    full_attn: True
    fwl: False
    norm_e: True
    sparse: False
    use: True
    use_bias: False
  attn_dropout: 0.2
  batch_norm: True
  bigbird:
    add_cross_attention: False
    attention_type: block_sparse
    block_size: 3
    chunk_size_feed_forward: 0
    hidden_act: relu
    is_decoder: False
    layer_norm_eps: 1e-06
    max_position_embeddings: 128
    num_random_blocks: 3
    use_bias: False
  bn_momentum: 0.1
  bn_no_runner: False
  dim_hidden: 100
  dropout: 0.0
  full_graph: True
  gamma: 1e-05
  layer_norm: False
  layer_type: GritTransformer
  layers: 4
  n_heads: 3
  pna_degrees: []
  residual: True
  update_e: True
mem:
  inplace: False
metric_agg: argmax
metric_best: auc
mlflow:
  name: molbace-GRIT-RRWP
  project: Exp
  use: False
model:
  edge_decoding: dot
  graph_pooling: add
  loss_fun: cross_entropy
  match_upper: True
  size_average: mean
  thresh: 0.5
  type: GritTransformer
name_tag: 
num_threads: 6
num_workers: 0
optim:
  base_lr: 0.01
  batch_accumulation: 1
  clip_grad_norm: False
  early_stop_by_lr: False
  early_stop_by_perf: False
  lr_decay: 0.1
  max_epoch: 50
  min_lr: 0.0
  min_lr_mode: threshold
  momentum: 0.9
  num_cycles: 0.5
  num_warmup_epochs: 50
  optimizer: adam
  reduce_factor: 0.5
  schedule_patience: 10
  scheduler: cos
  steps: [30, 60, 90]
  stop_patience: 100
  weight_decay: 0.0005
out_dir: results/molbace-GRIT-RRWP
posenc_ElstaticSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: range(10)
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_EquivStableLapPE:
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  raw_norm_type: none
posenc_HKdiagSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: 
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_LapPE:
  dim_pe: 16
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_RRWP:
  add_identity: True
  add_inverse: False
  add_node_attr: False
  dim_pe: 16
  enable: True
  ksteps: 21
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
  spd: False
posenc_RWSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: 
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_SignNet:
  dim_pe: 16
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  phi_hidden_dim: 64
  phi_out_dim: 4
  post_layers: 0
  raw_norm_type: none
pretrained:
  dir: 
  freeze_main: False
  reset_prediction_head: True
print: both
round: 5
run_dir: results/molbace-GRIT-RRWP/1
run_id: 1
run_multiple_splits: []
seed: 1
share:
  dim_in: 9
  dim_out: 2
  num_splits: 3
tensorboard_agg: True
tensorboard_each_run: True
train:
  auto_resume: False
  batch_size: 34
  ckpt_best: True
  ckpt_clean: True
  ckpt_period: 100
  enable_ckpt: True
  epoch_resume: -1
  eval_period: 1
  iter_per_epoch: 32
  mode: custom
  neighbor_sizes: [20, 15, 10, 5]
  node_per_graph: 32
  radius: extend
  sample_node: False
  sampler: full_batch
  skip_train_eval: False
  walk_length: 4
val:
  node_per_graph: 32
  radius: extend
  sample_node: False
  sampler: full_batch
view_emb: False
wandb:
  entity: gtransformers
  name: 
  project: molbace
  use: False
work_dir: /Users/alexandre/Cours/M1/internship/GRIT
Num parameters: 490650
Start from epoch 0
train: {'epoch': 0, 'time_epoch': 65.28875, 'eta': 3199.14869, 'eta_hours': 0.88865, 'loss': 2.03768863, 'lr': 0.01, 'params': 490650, 'time_iter': 1.81358, 'accuracy': 0.5438, 'precision': 0.41964, 'recall': 0.39167, 'f1': 0.40517, 'auc': 0.52658}
...computing epoch stats took: 0.02s
val: {'epoch': 0, 'time_epoch': 2.91359, 'loss': 6.08491712, 'lr': 0, 'params': 490650, 'time_iter': 0.58272, 'accuracy': 0.13907, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.39267}
...computing epoch stats took: 0.01s
test: {'epoch': 0, 'time_epoch': 2.81783, 'loss': 4.02653636, 'lr': 0, 'params': 490650, 'time_iter': 0.56357, 'accuracy': 0.46711, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.25891}
...computing epoch stats took: 0.02s
> Epoch 0: took 71.1s (avg 71.1s) | Best so far: epoch 0	train_loss: 2.0377 train_auc: 0.5266	val_loss: 6.0849 val_auc: 0.3927	test_loss: 4.0265 test_auc: 0.2589
-----------------------------------------------------------
train: {'epoch': 1, 'time_epoch': 68.2744, 'eta': 3205.51558, 'eta_hours': 0.89042, 'loss': 0.59984714, 'lr': 0.00999013, 'params': 490650, 'time_iter': 1.89651, 'accuracy': 0.67603, 'precision': 0.63174, 'recall': 0.43958, 'f1': 0.51843, 'auc': 0.73092}
...computing epoch stats took: 0.03s
val: {'epoch': 1, 'time_epoch': 3.40814, 'loss': 0.78280992, 'lr': 0, 'params': 490650, 'time_iter': 0.68163, 'accuracy': 0.55629, 'precision': 0.90909, 'recall': 0.53846, 'f1': 0.67633, 'auc': 0.69414}
...computing epoch stats took: 0.02s
test: {'epoch': 1, 'time_epoch': 3.34667, 'loss': 0.9087579, 'lr': 0, 'params': 490650, 'time_iter': 0.66933, 'accuracy': 0.63158, 'precision': 0.73585, 'recall': 0.48148, 'f1': 0.58209, 'auc': 0.72892}
...computing epoch stats took: 0.02s
> Epoch 1: took 75.1s (avg 73.1s) | Best so far: epoch 1	train_loss: 0.5998 train_auc: 0.7309	val_loss: 0.7828 val_auc: 0.6941	test_loss: 0.9088 test_auc: 0.7289
-----------------------------------------------------------
train: {'epoch': 2, 'time_epoch': 64.3275, 'eta': 3100.28686, 'eta_hours': 0.86119, 'loss': 0.5559317, 'lr': 0.00996057, 'params': 490650, 'time_iter': 1.78688, 'accuracy': 0.7124, 'precision': 0.65942, 'recall': 0.56875, 'f1': 0.61074, 'auc': 0.77773}
...computing epoch stats took: 0.02s
val: {'epoch': 2, 'time_epoch': 2.73568, 'loss': 0.62057573, 'lr': 0, 'params': 490650, 'time_iter': 0.54714, 'accuracy': 0.69536, 'precision': 0.86207, 'recall': 0.76923, 'f1': 0.81301, 'auc': 0.57179}
...computing epoch stats took: 0.01s
test: {'epoch': 2, 'time_epoch': 2.64861, 'loss': 0.72832166, 'lr': 0, 'params': 490650, 'time_iter': 0.52972, 'accuracy': 0.61842, 'precision': 0.70175, 'recall': 0.49383, 'f1': 0.57971, 'auc': 0.69171}
...computing epoch stats took: 0.01s
> Epoch 2: took 69.8s (avg 72.0s) | Best so far: epoch 1	train_loss: 0.5998 train_auc: 0.7309	val_loss: 0.7828 val_auc: 0.6941	test_loss: 0.9088 test_auc: 0.7289
-----------------------------------------------------------
train: {'epoch': 3, 'time_epoch': 64.3547, 'eta': 3015.82157, 'eta_hours': 0.83773, 'loss': 0.56819514, 'lr': 0.00991144, 'params': 490650, 'time_iter': 1.78763, 'accuracy': 0.71736, 'precision': 0.65682, 'recall': 0.60208, 'f1': 0.62826, 'auc': 0.77624}
val: {'epoch': 3, 'time_epoch': 2.72169, 'loss': 0.63024605, 'lr': 0, 'params': 490650, 'time_iter': 0.54434, 'accuracy': 0.60927, 'precision': 0.91765, 'recall': 0.6, 'f1': 0.72558, 'auc': 0.67582}
test: {'epoch': 3, 'time_epoch': 2.63298, 'loss': 0.65906429, 'lr': 0, 'params': 490650, 'time_iter': 0.5266, 'accuracy': 0.625, 'precision': 0.78571, 'recall': 0.40741, 'f1': 0.53659, 'auc': 0.75378}
> Epoch 3: took 69.8s (avg 71.4s) | Best so far: epoch 1	train_loss: 0.5998 train_auc: 0.7309	val_loss: 0.7828 val_auc: 0.6941	test_loss: 0.9088 test_auc: 0.7289
-----------------------------------------------------------
train: {'epoch': 4, 'time_epoch': 64.28529, 'eta': 2938.7758, 'eta_hours': 0.81633, 'loss': 0.5473315, 'lr': 0.00984292, 'params': 490650, 'time_iter': 1.7857, 'accuracy': 0.72562, 'precision': 0.6729, 'recall': 0.6, 'f1': 0.63436, 'auc': 0.78834}
val: {'epoch': 4, 'time_epoch': 2.75339, 'loss': 0.79004059, 'lr': 0, 'params': 490650, 'time_iter': 0.55068, 'accuracy': 0.52318, 'precision': 0.90278, 'recall': 0.5, 'f1': 0.64356, 'auc': 0.60952}
test: {'epoch': 4, 'time_epoch': 2.64629, 'loss': 0.82514399, 'lr': 0, 'params': 490650, 'time_iter': 0.52926, 'accuracy': 0.55921, 'precision': 0.71875, 'recall': 0.28395, 'f1': 0.40708, 'auc': 0.70457}
> Epoch 4: took 69.7s (avg 71.1s) | Best so far: epoch 1	train_loss: 0.5998 train_auc: 0.7309	val_loss: 0.7828 val_auc: 0.6941	test_loss: 0.9088 test_auc: 0.7289
-----------------------------------------------------------
train: {'epoch': 5, 'time_epoch': 64.03024, 'eta': 2864.11311, 'eta_hours': 0.79559, 'loss': 0.53960447, 'lr': 0.00975528, 'params': 490650, 'time_iter': 1.77862, 'accuracy': 0.74132, 'precision': 0.6788, 'recall': 0.66042, 'f1': 0.66948, 'auc': 0.80009}
val: {'epoch': 5, 'time_epoch': 2.70995, 'loss': 2.71324543, 'lr': 0, 'params': 490650, 'time_iter': 0.54199, 'accuracy': 0.13907, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.4978}
test: {'epoch': 5, 'time_epoch': 2.64846, 'loss': 1.97963878, 'lr': 0, 'params': 490650, 'time_iter': 0.52969, 'accuracy': 0.46711, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.42201}
> Epoch 5: took 69.5s (avg 70.8s) | Best so far: epoch 1	train_loss: 0.5998 train_auc: 0.7309	val_loss: 0.7828 val_auc: 0.6941	test_loss: 0.9088 test_auc: 0.7289
-----------------------------------------------------------
train: {'epoch': 6, 'time_epoch': 63.65799, 'eta': 2790.20162, 'eta_hours': 0.77506, 'loss': 0.53857754, 'lr': 0.00964888, 'params': 490650, 'time_iter': 1.76828, 'accuracy': 0.73554, 'precision': 0.70619, 'recall': 0.57083, 'f1': 0.63134, 'auc': 0.79686}
val: {'epoch': 6, 'time_epoch': 2.7162, 'loss': 0.47913426, 'lr': 0, 'params': 490650, 'time_iter': 0.54324, 'accuracy': 0.74834, 'precision': 0.88983, 'recall': 0.80769, 'f1': 0.84677, 'auc': 0.71575}
test: {'epoch': 6, 'time_epoch': 2.62705, 'loss': 0.58892169, 'lr': 0, 'params': 490650, 'time_iter': 0.52541, 'accuracy': 0.73684, 'precision': 0.76623, 'recall': 0.7284, 'f1': 0.74684, 'auc': 0.80838}
> Epoch 6: took 69.1s (avg 70.6s) | Best so far: epoch 6	train_loss: 0.5386 train_auc: 0.7969	val_loss: 0.4791 val_auc: 0.7157	test_loss: 0.5889 test_auc: 0.8084
-----------------------------------------------------------
train: {'epoch': 7, 'time_epoch': 63.4381, 'eta': 2717.69909, 'eta_hours': 0.75492, 'loss': 0.53632038, 'lr': 0.00952414, 'params': 490650, 'time_iter': 1.76217, 'accuracy': 0.75289, 'precision': 0.68973, 'recall': 0.68542, 'f1': 0.68757, 'auc': 0.80329}
val: {'epoch': 7, 'time_epoch': 2.70764, 'loss': 0.44566523, 'lr': 0, 'params': 490650, 'time_iter': 0.54153, 'accuracy': 0.78808, 'precision': 0.85, 'recall': 0.91538, 'f1': 0.88148, 'auc': 0.70586}
test: {'epoch': 7, 'time_epoch': 2.62721, 'loss': 0.69801401, 'lr': 0, 'params': 490650, 'time_iter': 0.52544, 'accuracy': 0.76316, 'precision': 0.72727, 'recall': 0.88889, 'f1': 0.8, 'auc': 0.80664}
> Epoch 7: took 68.8s (avg 70.4s) | Best so far: epoch 6	train_loss: 0.5386 train_auc: 0.7969	val_loss: 0.4791 val_auc: 0.7157	test_loss: 0.5889 test_auc: 0.8084
-----------------------------------------------------------
train: {'epoch': 8, 'time_epoch': 64.70994, 'eta': 2653.00481, 'eta_hours': 0.73695, 'loss': 0.49506298, 'lr': 0.00938153, 'params': 490650, 'time_iter': 1.7975, 'accuracy': 0.76033, 'precision': 0.70742, 'recall': 0.675, 'f1': 0.69083, 'auc': 0.83519}
val: {'epoch': 8, 'time_epoch': 2.75995, 'loss': 1.39590185, 'lr': 0, 'params': 490650, 'time_iter': 0.55199, 'accuracy': 0.18543, 'precision': 1.0, 'recall': 0.05385, 'f1': 0.10219, 'auc': 0.61062}
test: {'epoch': 8, 'time_epoch': 2.68872, 'loss': 1.17071467, 'lr': 0, 'params': 490650, 'time_iter': 0.53774, 'accuracy': 0.47368, 'precision': 1.0, 'recall': 0.01235, 'f1': 0.02439, 'auc': 0.64441}
> Epoch 8: took 70.2s (avg 70.3s) | Best so far: epoch 6	train_loss: 0.5386 train_auc: 0.7969	val_loss: 0.4791 val_auc: 0.7157	test_loss: 0.5889 test_auc: 0.8084
-----------------------------------------------------------
train: {'epoch': 9, 'time_epoch': 64.04504, 'eta': 2585.64781, 'eta_hours': 0.71824, 'loss': 0.53696244, 'lr': 0.00922164, 'params': 490650, 'time_iter': 1.77903, 'accuracy': 0.72645, 'precision': 0.6778, 'recall': 0.59167, 'f1': 0.63181, 'auc': 0.80401}
val: {'epoch': 9, 'time_epoch': 2.73685, 'loss': 0.4876915, 'lr': 0, 'params': 490650, 'time_iter': 0.54737, 'accuracy': 0.75497, 'precision': 0.89744, 'recall': 0.80769, 'f1': 0.8502, 'auc': 0.74542}
test: {'epoch': 9, 'time_epoch': 2.63614, 'loss': 0.54836341, 'lr': 0, 'params': 490650, 'time_iter': 0.52723, 'accuracy': 0.75, 'precision': 0.77215, 'recall': 0.75309, 'f1': 0.7625, 'auc': 0.80508}
> Epoch 9: took 69.5s (avg 70.3s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 10, 'time_epoch': 65.0949, 'eta': 2522.61521, 'eta_hours': 0.70073, 'loss': 0.51605806, 'lr': 0.00904508, 'params': 490650, 'time_iter': 1.80819, 'accuracy': 0.75289, 'precision': 0.6989, 'recall': 0.6625, 'f1': 0.68021, 'auc': 0.81749}
val: {'epoch': 10, 'time_epoch': 2.79389, 'loss': 0.92396735, 'lr': 0, 'params': 490650, 'time_iter': 0.55878, 'accuracy': 0.34437, 'precision': 0.91892, 'recall': 0.26154, 'f1': 0.40719, 'auc': 0.66667}
test: {'epoch': 10, 'time_epoch': 2.70508, 'loss': 0.82854898, 'lr': 0, 'params': 490650, 'time_iter': 0.54102, 'accuracy': 0.50658, 'precision': 0.6875, 'recall': 0.1358, 'f1': 0.2268, 'auc': 0.74005}
> Epoch 10: took 70.7s (avg 70.3s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 11, 'time_epoch': 64.39087, 'eta': 2457.00947, 'eta_hours': 0.6825, 'loss': 0.50722101, 'lr': 0.00885257, 'params': 490650, 'time_iter': 1.78864, 'accuracy': 0.76612, 'precision': 0.71648, 'recall': 0.67917, 'f1': 0.69733, 'auc': 0.82907}
val: {'epoch': 11, 'time_epoch': 2.91643, 'loss': 0.67406393, 'lr': 0, 'params': 490650, 'time_iter': 0.58329, 'accuracy': 0.64238, 'precision': 0.88776, 'recall': 0.66923, 'f1': 0.76316, 'auc': 0.68059}
test: {'epoch': 11, 'time_epoch': 2.71844, 'loss': 0.72735473, 'lr': 0, 'params': 490650, 'time_iter': 0.54369, 'accuracy': 0.69737, 'precision': 0.77778, 'recall': 0.60494, 'f1': 0.68056, 'auc': 0.79151}
> Epoch 11: took 70.1s (avg 70.3s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 12, 'time_epoch': 64.26362, 'eta': 2391.22844, 'eta_hours': 0.66423, 'loss': 0.49803938, 'lr': 0.00864484, 'params': 490650, 'time_iter': 1.7851, 'accuracy': 0.77934, 'precision': 0.72611, 'recall': 0.7125, 'f1': 0.71924, 'auc': 0.83067}
val: {'epoch': 12, 'time_epoch': 2.6754, 'loss': 1.01499104, 'lr': 0, 'params': 490650, 'time_iter': 0.53508, 'accuracy': 0.38411, 'precision': 0.95122, 'recall': 0.3, 'f1': 0.45614, 'auc': 0.62454}
test: {'epoch': 12, 'time_epoch': 2.59855, 'loss': 0.90403238, 'lr': 0, 'params': 490650, 'time_iter': 0.51971, 'accuracy': 0.50658, 'precision': 0.66667, 'recall': 0.14815, 'f1': 0.24242, 'auc': 0.71466}
> Epoch 12: took 69.6s (avg 70.2s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 13, 'time_epoch': 64.81891, 'eta': 2327.09208, 'eta_hours': 0.64641, 'loss': 0.53333792, 'lr': 0.00842274, 'params': 490650, 'time_iter': 1.80053, 'accuracy': 0.75041, 'precision': 0.70227, 'recall': 0.64375, 'f1': 0.67174, 'auc': 0.80514}
val: {'epoch': 13, 'time_epoch': 2.7056, 'loss': 1.97282728, 'lr': 0, 'params': 490650, 'time_iter': 0.54112, 'accuracy': 0.13907, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.58278}
test: {'epoch': 13, 'time_epoch': 2.60276, 'loss': 1.43658969, 'lr': 0, 'params': 490650, 'time_iter': 0.52055, 'accuracy': 0.46711, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.51956}
> Epoch 13: took 70.2s (avg 70.2s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 14, 'time_epoch': 64.59624, 'eta': 2262.34515, 'eta_hours': 0.62843, 'loss': 0.49226315, 'lr': 0.00818712, 'params': 490650, 'time_iter': 1.79434, 'accuracy': 0.77934, 'precision': 0.74825, 'recall': 0.66875, 'f1': 0.70627, 'auc': 0.83766}
val: {'epoch': 14, 'time_epoch': 2.71635, 'loss': 0.9422877, 'lr': 0, 'params': 490650, 'time_iter': 0.54327, 'accuracy': 0.47682, 'precision': 0.96364, 'recall': 0.40769, 'f1': 0.57297, 'auc': 0.65604}
test: {'epoch': 14, 'time_epoch': 2.68865, 'loss': 0.78961053, 'lr': 0, 'params': 490650, 'time_iter': 0.53773, 'accuracy': 0.53947, 'precision': 0.7619, 'recall': 0.19753, 'f1': 0.31373, 'auc': 0.80021}
> Epoch 14: took 70.1s (avg 70.2s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 15, 'time_epoch': 64.02246, 'eta': 2196.39776, 'eta_hours': 0.61011, 'loss': 0.49445056, 'lr': 0.00793893, 'params': 490650, 'time_iter': 1.7784, 'accuracy': 0.76612, 'precision': 0.71648, 'recall': 0.67917, 'f1': 0.69733, 'auc': 0.83537}
val: {'epoch': 15, 'time_epoch': 2.67753, 'loss': 0.50386716, 'lr': 0, 'params': 490650, 'time_iter': 0.53551, 'accuracy': 0.75497, 'precision': 0.8843, 'recall': 0.82308, 'f1': 0.85259, 'auc': 0.65128}
test: {'epoch': 15, 'time_epoch': 2.58373, 'loss': 0.59669854, 'lr': 0, 'params': 490650, 'time_iter': 0.51675, 'accuracy': 0.73684, 'precision': 0.74699, 'recall': 0.76543, 'f1': 0.7561, 'auc': 0.7903}
> Epoch 15: took 69.3s (avg 70.2s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 16, 'time_epoch': 64.05323, 'eta': 2130.73659, 'eta_hours': 0.59187, 'loss': 0.52247086, 'lr': 0.00767913, 'params': 490650, 'time_iter': 1.77926, 'accuracy': 0.74463, 'precision': 0.69746, 'recall': 0.62917, 'f1': 0.66156, 'auc': 0.81345}
val: {'epoch': 16, 'time_epoch': 2.65624, 'loss': 3.30644565, 'lr': 0, 'params': 490650, 'time_iter': 0.53125, 'accuracy': 0.13907, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.63919}
test: {'epoch': 16, 'time_epoch': 2.59935, 'loss': 2.18544667, 'lr': 0, 'params': 490650, 'time_iter': 0.51987, 'accuracy': 0.46711, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc': 0.67032}
> Epoch 16: took 69.4s (avg 70.1s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 17, 'time_epoch': 63.1605, 'eta': 2063.66699, 'eta_hours': 0.57324, 'loss': 0.49539964, 'lr': 0.00740877, 'params': 490650, 'time_iter': 1.75446, 'accuracy': 0.77769, 'precision': 0.73602, 'recall': 0.68542, 'f1': 0.70982, 'auc': 0.83349}
val: {'epoch': 17, 'time_epoch': 2.6704, 'loss': 0.68203045, 'lr': 0, 'params': 490650, 'time_iter': 0.53408, 'accuracy': 0.84768, 'precision': 0.85906, 'recall': 0.98462, 'f1': 0.91756, 'auc': 0.73297}
test: {'epoch': 17, 'time_epoch': 2.59875, 'loss': 1.30035651, 'lr': 0, 'params': 490650, 'time_iter': 0.51975, 'accuracy': 0.66447, 'precision': 0.61538, 'recall': 0.98765, 'f1': 0.75829, 'auc': 0.8023}
> Epoch 17: took 68.5s (avg 70.0s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 18, 'time_epoch': 62.69341, 'eta': 1996.24679, 'eta_hours': 0.55451, 'loss': 0.49234661, 'lr': 0.0071289, 'params': 490650, 'time_iter': 1.74148, 'accuracy': 0.77603, 'precision': 0.72668, 'recall': 0.69792, 'f1': 0.71201, 'auc': 0.83851}
val: {'epoch': 18, 'time_epoch': 2.65581, 'loss': 0.54971128, 'lr': 0, 'params': 490650, 'time_iter': 0.53116, 'accuracy': 0.68212, 'precision': 0.86607, 'recall': 0.74615, 'f1': 0.80165, 'auc': 0.64762}
test: {'epoch': 18, 'time_epoch': 2.59297, 'loss': 0.62776421, 'lr': 0, 'params': 490650, 'time_iter': 0.51859, 'accuracy': 0.65789, 'precision': 0.76364, 'recall': 0.51852, 'f1': 0.61765, 'auc': 0.751}
> Epoch 18: took 68.0s (avg 69.9s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 19, 'time_epoch': 63.51499, 'eta': 1930.53162, 'eta_hours': 0.53626, 'loss': 0.47608562, 'lr': 0.00684062, 'params': 490650, 'time_iter': 1.76431, 'accuracy': 0.78182, 'precision': 0.73176, 'recall': 0.71042, 'f1': 0.72093, 'auc': 0.84793}
val: {'epoch': 19, 'time_epoch': 2.66466, 'loss': 1.06134809, 'lr': 0, 'params': 490650, 'time_iter': 0.53293, 'accuracy': 0.42384, 'precision': 0.87719, 'recall': 0.38462, 'f1': 0.53476, 'auc': 0.55421}
test: {'epoch': 19, 'time_epoch': 2.59415, 'loss': 1.13336685, 'lr': 0, 'params': 490650, 'time_iter': 0.51883, 'accuracy': 0.53289, 'precision': 0.75, 'recall': 0.18519, 'f1': 0.29703, 'auc': 0.59903}
> Epoch 19: took 68.8s (avg 69.9s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 20, 'time_epoch': 62.65978, 'eta': 1863.845, 'eta_hours': 0.51773, 'loss': 0.45772023, 'lr': 0.00654508, 'params': 490650, 'time_iter': 1.74055, 'accuracy': 0.79008, 'precision': 0.7545, 'recall': 0.69792, 'f1': 0.72511, 'auc': 0.86435}
val: {'epoch': 20, 'time_epoch': 2.63475, 'loss': 0.90480414, 'lr': 0, 'params': 490650, 'time_iter': 0.52695, 'accuracy': 0.55629, 'precision': 0.89873, 'recall': 0.54615, 'f1': 0.67943, 'auc': 0.64542}
test: {'epoch': 20, 'time_epoch': 2.56339, 'loss': 0.85488666, 'lr': 0, 'params': 490650, 'time_iter': 0.51268, 'accuracy': 0.65789, 'precision': 0.77358, 'recall': 0.50617, 'f1': 0.61194, 'auc': 0.7816}
> Epoch 20: took 67.9s (avg 69.8s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 21, 'time_epoch': 62.86541, 'eta': 1797.78616, 'eta_hours': 0.49939, 'loss': 0.47515579, 'lr': 0.00624345, 'params': 490650, 'time_iter': 1.74626, 'accuracy': 0.78512, 'precision': 0.73707, 'recall': 0.7125, 'f1': 0.72458, 'auc': 0.85055}
val: {'epoch': 21, 'time_epoch': 2.65854, 'loss': 0.45612081, 'lr': 0, 'params': 490650, 'time_iter': 0.53171, 'accuracy': 0.76821, 'precision': 0.8626, 'recall': 0.86923, 'f1': 0.8659, 'auc': 0.6967}
test: {'epoch': 21, 'time_epoch': 2.59147, 'loss': 0.66486405, 'lr': 0, 'params': 490650, 'time_iter': 0.51829, 'accuracy': 0.74342, 'precision': 0.74419, 'recall': 0.79012, 'f1': 0.76647, 'auc': 0.79082}
> Epoch 21: took 68.2s (avg 69.7s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 22, 'time_epoch': 63.14612, 'eta': 1732.33455, 'eta_hours': 0.4812, 'loss': 0.47211717, 'lr': 0.00593691, 'params': 490650, 'time_iter': 1.75406, 'accuracy': 0.7843, 'precision': 0.72671, 'recall': 0.73125, 'f1': 0.72897, 'auc': 0.84975}
val: {'epoch': 22, 'time_epoch': 2.66627, 'loss': 0.69548515, 'lr': 0, 'params': 490650, 'time_iter': 0.53325, 'accuracy': 0.68874, 'precision': 0.89524, 'recall': 0.72308, 'f1': 0.8, 'auc': 0.65348}
test: {'epoch': 22, 'time_epoch': 2.59458, 'loss': 0.61602079, 'lr': 0, 'params': 490650, 'time_iter': 0.51892, 'accuracy': 0.64474, 'precision': 0.77551, 'recall': 0.46914, 'f1': 0.58462, 'auc': 0.78769}
> Epoch 22: took 68.5s (avg 69.6s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 23, 'time_epoch': 63.03705, 'eta': 1666.95689, 'eta_hours': 0.46304, 'loss': 0.44370222, 'lr': 0.00562667, 'params': 490650, 'time_iter': 1.75103, 'accuracy': 0.79421, 'precision': 0.74732, 'recall': 0.72708, 'f1': 0.73706, 'auc': 0.86715}
val: {'epoch': 23, 'time_epoch': 2.66515, 'loss': 0.62016975, 'lr': 0, 'params': 490650, 'time_iter': 0.53303, 'accuracy': 0.66887, 'precision': 0.88462, 'recall': 0.70769, 'f1': 0.78632, 'auc': 0.66777}
test: {'epoch': 23, 'time_epoch': 2.59403, 'loss': 0.65364515, 'lr': 0, 'params': 490650, 'time_iter': 0.51881, 'accuracy': 0.65132, 'precision': 0.80435, 'recall': 0.45679, 'f1': 0.58268, 'auc': 0.77882}
> Epoch 23: took 68.4s (avg 69.6s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 24, 'time_epoch': 62.43973, 'eta': 1601.16917, 'eta_hours': 0.44477, 'loss': 0.45749339, 'lr': 0.00531395, 'params': 490650, 'time_iter': 1.73444, 'accuracy': 0.80661, 'precision': 0.76395, 'recall': 0.74167, 'f1': 0.75264, 'auc': 0.86357}
val: {'epoch': 24, 'time_epoch': 2.66347, 'loss': 0.46444908, 'lr': 0, 'params': 490650, 'time_iter': 0.53269, 'accuracy': 0.81457, 'precision': 0.85915, 'recall': 0.93846, 'f1': 0.89706, 'auc': 0.65165}
test: {'epoch': 24, 'time_epoch': 2.58885, 'loss': 0.61195462, 'lr': 0, 'params': 490650, 'time_iter': 0.51777, 'accuracy': 0.71711, 'precision': 0.70213, 'recall': 0.81481, 'f1': 0.75429, 'auc': 0.73865}
> Epoch 24: took 67.8s (avg 69.5s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 25, 'time_epoch': 62.69294, 'eta': 1535.87271, 'eta_hours': 0.42663, 'loss': 0.44507557, 'lr': 0.005, 'params': 490650, 'time_iter': 1.74147, 'accuracy': 0.80248, 'precision': 0.75476, 'recall': 0.74375, 'f1': 0.74921, 'auc': 0.86804}
val: {'epoch': 25, 'time_epoch': 2.66177, 'loss': 0.77237231, 'lr': 0, 'params': 490650, 'time_iter': 0.53235, 'accuracy': 0.63576, 'precision': 0.94118, 'recall': 0.61538, 'f1': 0.74419, 'auc': 0.71429}
test: {'epoch': 25, 'time_epoch': 2.59725, 'loss': 0.70155064, 'lr': 0, 'params': 490650, 'time_iter': 0.51945, 'accuracy': 0.625, 'precision': 0.77273, 'recall': 0.41975, 'f1': 0.544, 'auc': 0.82403}
> Epoch 25: took 68.0s (avg 69.5s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 26, 'time_epoch': 62.82384, 'eta': 1470.88062, 'eta_hours': 0.40858, 'loss': 0.42216115, 'lr': 0.00468605, 'params': 490650, 'time_iter': 1.74511, 'accuracy': 0.82149, 'precision': 0.77966, 'recall': 0.76667, 'f1': 0.77311, 'auc': 0.88344}
val: {'epoch': 26, 'time_epoch': 2.64764, 'loss': 0.70659145, 'lr': 0, 'params': 490650, 'time_iter': 0.52953, 'accuracy': 0.66887, 'precision': 0.90816, 'recall': 0.68462, 'f1': 0.7807, 'auc': 0.66813}
test: {'epoch': 26, 'time_epoch': 2.57871, 'loss': 0.66565919, 'lr': 0, 'params': 490650, 'time_iter': 0.51574, 'accuracy': 0.65132, 'precision': 0.86842, 'recall': 0.40741, 'f1': 0.55462, 'auc': 0.7976}
> Epoch 26: took 68.1s (avg 69.4s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 27, 'time_epoch': 62.56409, 'eta': 1405.83931, 'eta_hours': 0.39051, 'loss': 0.44387629, 'lr': 0.00437333, 'params': 490650, 'time_iter': 1.73789, 'accuracy': 0.7876, 'precision': 0.72345, 'recall': 0.75208, 'f1': 0.73749, 'auc': 0.86792}
val: {'epoch': 27, 'time_epoch': 2.65291, 'loss': 0.4169395, 'lr': 0, 'params': 490650, 'time_iter': 0.53058, 'accuracy': 0.80795, 'precision': 0.85315, 'recall': 0.93846, 'f1': 0.89377, 'auc': 0.72491}
test: {'epoch': 27, 'time_epoch': 2.57456, 'loss': 0.64329939, 'lr': 0, 'params': 490650, 'time_iter': 0.51491, 'accuracy': 0.73684, 'precision': 0.67521, 'recall': 0.97531, 'f1': 0.79798, 'auc': 0.82316}
> Epoch 27: took 67.9s (avg 69.4s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 28, 'time_epoch': 62.22718, 'eta': 1340.72488, 'eta_hours': 0.37242, 'loss': 0.42665871, 'lr': 0.00406309, 'params': 490650, 'time_iter': 1.72853, 'accuracy': 0.81322, 'precision': 0.76132, 'recall': 0.77083, 'f1': 0.76605, 'auc': 0.87848}
val: {'epoch': 28, 'time_epoch': 2.64931, 'loss': 0.85592922, 'lr': 0, 'params': 490650, 'time_iter': 0.52986, 'accuracy': 0.51656, 'precision': 0.90141, 'recall': 0.49231, 'f1': 0.63682, 'auc': 0.61502}
test: {'epoch': 28, 'time_epoch': 2.59726, 'loss': 0.86404401, 'lr': 0, 'params': 490650, 'time_iter': 0.51945, 'accuracy': 0.57895, 'precision': 0.7931, 'recall': 0.28395, 'f1': 0.41818, 'auc': 0.73344}
> Epoch 28: took 67.5s (avg 69.3s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 29, 'time_epoch': 62.50854, 'eta': 1275.9905, 'eta_hours': 0.35444, 'loss': 0.42013977, 'lr': 0.00375655, 'params': 490650, 'time_iter': 1.73635, 'accuracy': 0.8124, 'precision': 0.77088, 'recall': 0.75, 'f1': 0.7603, 'auc': 0.88538}
val: {'epoch': 29, 'time_epoch': 2.65289, 'loss': 0.65809569, 'lr': 0, 'params': 490650, 'time_iter': 0.53058, 'accuracy': 0.68212, 'precision': 0.90196, 'recall': 0.70769, 'f1': 0.7931, 'auc': 0.6337}
test: {'epoch': 29, 'time_epoch': 2.5907, 'loss': 0.75614874, 'lr': 0, 'params': 490650, 'time_iter': 0.51814, 'accuracy': 0.64474, 'precision': 0.81395, 'recall': 0.4321, 'f1': 0.56452, 'auc': 0.7623}
> Epoch 29: took 67.8s (avg 69.2s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 30, 'time_epoch': 62.88148, 'eta': 1211.6283, 'eta_hours': 0.33656, 'loss': 0.39925133, 'lr': 0.00345492, 'params': 490650, 'time_iter': 1.74671, 'accuracy': 0.82231, 'precision': 0.76031, 'recall': 0.80625, 'f1': 0.78261, 'auc': 0.89413}
val: {'epoch': 30, 'time_epoch': 2.66472, 'loss': 0.48727335, 'lr': 0, 'params': 490650, 'time_iter': 0.53294, 'accuracy': 0.80132, 'precision': 0.86765, 'recall': 0.90769, 'f1': 0.88722, 'auc': 0.69451}
test: {'epoch': 30, 'time_epoch': 2.59736, 'loss': 0.63330416, 'lr': 0, 'params': 490650, 'time_iter': 0.51947, 'accuracy': 0.71711, 'precision': 0.69792, 'recall': 0.82716, 'f1': 0.75706, 'auc': 0.80212}
> Epoch 30: took 68.2s (avg 69.2s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 31, 'time_epoch': 63.23733, 'eta': 1147.55882, 'eta_hours': 0.31877, 'loss': 0.40381656, 'lr': 0.00315938, 'params': 490650, 'time_iter': 1.75659, 'accuracy': 0.82066, 'precision': 0.78525, 'recall': 0.75417, 'f1': 0.76939, 'auc': 0.89382}
val: {'epoch': 31, 'time_epoch': 2.66266, 'loss': 1.48872907, 'lr': 0, 'params': 490650, 'time_iter': 0.53253, 'accuracy': 0.33113, 'precision': 1.0, 'recall': 0.22308, 'f1': 0.36478, 'auc': 0.63956}
test: {'epoch': 31, 'time_epoch': 2.59078, 'loss': 1.47065891, 'lr': 0, 'params': 490650, 'time_iter': 0.51816, 'accuracy': 0.50658, 'precision': 0.875, 'recall': 0.08642, 'f1': 0.1573, 'auc': 0.7117}
> Epoch 31: took 68.6s (avg 69.2s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 32, 'time_epoch': 63.10009, 'eta': 1083.46906, 'eta_hours': 0.30096, 'loss': 0.40665612, 'lr': 0.0028711, 'params': 490650, 'time_iter': 1.75278, 'accuracy': 0.80992, 'precision': 0.75304, 'recall': 0.775, 'f1': 0.76386, 'auc': 0.89021}
val: {'epoch': 32, 'time_epoch': 2.66851, 'loss': 0.58767382, 'lr': 0, 'params': 490650, 'time_iter': 0.5337, 'accuracy': 0.76821, 'precision': 0.88618, 'recall': 0.83846, 'f1': 0.86166, 'auc': 0.68352}
test: {'epoch': 32, 'time_epoch': 2.59679, 'loss': 0.63759428, 'lr': 0, 'params': 490650, 'time_iter': 0.51936, 'accuracy': 0.75, 'precision': 0.76543, 'recall': 0.76543, 'f1': 0.76543, 'auc': 0.81986}
> Epoch 32: took 68.4s (avg 69.2s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 33, 'time_epoch': 63.32375, 'eta': 1019.54278, 'eta_hours': 0.28321, 'loss': 0.40320198, 'lr': 0.00259123, 'params': 490650, 'time_iter': 1.75899, 'accuracy': 0.81818, 'precision': 0.7766, 'recall': 0.76042, 'f1': 0.76842, 'auc': 0.89496}
val: {'epoch': 33, 'time_epoch': 2.66529, 'loss': 0.59910218, 'lr': 0, 'params': 490650, 'time_iter': 0.53306, 'accuracy': 0.71523, 'precision': 0.88496, 'recall': 0.76923, 'f1': 0.82305, 'auc': 0.64176}
test: {'epoch': 33, 'time_epoch': 2.6071, 'loss': 0.60076148, 'lr': 0, 'params': 490650, 'time_iter': 0.52142, 'accuracy': 0.66447, 'precision': 0.75, 'recall': 0.55556, 'f1': 0.6383, 'auc': 0.78595}
> Epoch 33: took 68.7s (avg 69.1s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 34, 'time_epoch': 62.64869, 'eta': 955.36161, 'eta_hours': 0.26538, 'loss': 0.39410505, 'lr': 0.00232087, 'params': 490650, 'time_iter': 1.74024, 'accuracy': 0.82975, 'precision': 0.77846, 'recall': 0.79792, 'f1': 0.78807, 'auc': 0.89945}
val: {'epoch': 34, 'time_epoch': 2.6622, 'loss': 0.4531538, 'lr': 0, 'params': 490650, 'time_iter': 0.53244, 'accuracy': 0.80132, 'precision': 0.87879, 'recall': 0.89231, 'f1': 0.8855, 'auc': 0.67729}
test: {'epoch': 34, 'time_epoch': 2.58022, 'loss': 0.50898635, 'lr': 0, 'params': 490650, 'time_iter': 0.51604, 'accuracy': 0.79605, 'precision': 0.77174, 'recall': 0.87654, 'f1': 0.82081, 'auc': 0.83759}
> Epoch 34: took 68.0s (avg 69.1s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 35, 'time_epoch': 64.07918, 'eta': 891.82188, 'eta_hours': 0.24773, 'loss': 0.3713715, 'lr': 0.00206107, 'params': 490650, 'time_iter': 1.77998, 'accuracy': 0.84298, 'precision': 0.79234, 'recall': 0.81875, 'f1': 0.80533, 'auc': 0.90956}
val: {'epoch': 35, 'time_epoch': 2.70855, 'loss': 0.51977368, 'lr': 0, 'params': 490650, 'time_iter': 0.54171, 'accuracy': 0.77483, 'precision': 0.88095, 'recall': 0.85385, 'f1': 0.86719, 'auc': 0.67289}
test: {'epoch': 35, 'time_epoch': 2.60631, 'loss': 0.53536698, 'lr': 0, 'params': 490650, 'time_iter': 0.52126, 'accuracy': 0.75, 'precision': 0.81159, 'recall': 0.69136, 'f1': 0.74667, 'auc': 0.83794}
> Epoch 35: took 69.5s (avg 69.1s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 36, 'time_epoch': 63.65122, 'eta': 828.10263, 'eta_hours': 0.23003, 'loss': 0.38454421, 'lr': 0.00181288, 'params': 490650, 'time_iter': 1.76809, 'accuracy': 0.83058, 'precision': 0.77666, 'recall': 0.80417, 'f1': 0.79017, 'auc': 0.90236}
val: {'epoch': 36, 'time_epoch': 2.65191, 'loss': 1.12631274, 'lr': 0, 'params': 490650, 'time_iter': 0.53038, 'accuracy': 0.4702, 'precision': 0.98077, 'recall': 0.39231, 'f1': 0.56044, 'auc': 0.69011}
test: {'epoch': 36, 'time_epoch': 2.61139, 'loss': 0.97670441, 'lr': 0, 'params': 490650, 'time_iter': 0.52228, 'accuracy': 0.57895, 'precision': 0.94737, 'recall': 0.22222, 'f1': 0.36, 'auc': 0.82629}
> Epoch 36: took 69.0s (avg 69.1s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 37, 'time_epoch': 63.07081, 'eta': 764.20367, 'eta_hours': 0.21228, 'loss': 0.37940865, 'lr': 0.00157726, 'params': 490650, 'time_iter': 1.75197, 'accuracy': 0.83471, 'precision': 0.78, 'recall': 0.8125, 'f1': 0.79592, 'auc': 0.90376}
val: {'epoch': 37, 'time_epoch': 2.65588, 'loss': 0.62090627, 'lr': 0, 'params': 490650, 'time_iter': 0.53118, 'accuracy': 0.72848, 'precision': 0.89381, 'recall': 0.77692, 'f1': 0.83128, 'auc': 0.70623}
test: {'epoch': 37, 'time_epoch': 2.6149, 'loss': 0.66252099, 'lr': 0, 'params': 490650, 'time_iter': 0.52298, 'accuracy': 0.69079, 'precision': 0.80357, 'recall': 0.55556, 'f1': 0.65693, 'auc': 0.80855}
> Epoch 37: took 68.4s (avg 69.1s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 38, 'time_epoch': 63.17357, 'eta': 700.37617, 'eta_hours': 0.19455, 'loss': 0.38578176, 'lr': 0.00135516, 'params': 490650, 'time_iter': 1.75482, 'accuracy': 0.82149, 'precision': 0.77731, 'recall': 0.77083, 'f1': 0.77406, 'auc': 0.90162}
val: {'epoch': 38, 'time_epoch': 2.65651, 'loss': 0.53629287, 'lr': 0, 'params': 490650, 'time_iter': 0.5313, 'accuracy': 0.76821, 'precision': 0.88618, 'recall': 0.83846, 'f1': 0.86166, 'auc': 0.66374}
test: {'epoch': 38, 'time_epoch': 2.67914, 'loss': 0.55604868, 'lr': 0, 'params': 490650, 'time_iter': 0.53583, 'accuracy': 0.73684, 'precision': 0.7971, 'recall': 0.67901, 'f1': 0.73333, 'auc': 0.8242}
> Epoch 38: took 68.6s (avg 69.1s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 39, 'time_epoch': 63.8079, 'eta': 636.73994, 'eta_hours': 0.17687, 'loss': 0.3603588, 'lr': 0.00114743, 'params': 490650, 'time_iter': 1.77244, 'accuracy': 0.83306, 'precision': 0.778, 'recall': 0.81042, 'f1': 0.79388, 'auc': 0.9143}
val: {'epoch': 39, 'time_epoch': 2.69237, 'loss': 1.23529802, 'lr': 0, 'params': 490650, 'time_iter': 0.53847, 'accuracy': 0.49007, 'precision': 0.93443, 'recall': 0.43846, 'f1': 0.59686, 'auc': 0.68242}
test: {'epoch': 39, 'time_epoch': 2.75393, 'loss': 1.05288403, 'lr': 0, 'params': 490650, 'time_iter': 0.55079, 'accuracy': 0.58553, 'precision': 0.84615, 'recall': 0.2716, 'f1': 0.41121, 'auc': 0.82247}
> Epoch 39: took 69.3s (avg 69.1s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 40, 'time_epoch': 64.78196, 'eta': 573.30916, 'eta_hours': 0.15925, 'loss': 0.35455757, 'lr': 0.00095492, 'params': 490650, 'time_iter': 1.7995, 'accuracy': 0.85041, 'precision': 0.79722, 'recall': 0.83542, 'f1': 0.81587, 'auc': 0.91745}
val: {'epoch': 40, 'time_epoch': 2.73892, 'loss': 0.64386406, 'lr': 0, 'params': 490650, 'time_iter': 0.54778, 'accuracy': 0.68874, 'precision': 0.88785, 'recall': 0.73077, 'f1': 0.80169, 'auc': 0.69048}
test: {'epoch': 40, 'time_epoch': 2.70359, 'loss': 0.67316784, 'lr': 0, 'params': 490650, 'time_iter': 0.54072, 'accuracy': 0.74342, 'precision': 0.85, 'recall': 0.62963, 'f1': 0.7234, 'auc': 0.83116}
> Epoch 40: took 70.3s (avg 69.1s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 41, 'time_epoch': 64.58024, 'eta': 509.77561, 'eta_hours': 0.1416, 'loss': 0.34617382, 'lr': 0.00077836, 'params': 490650, 'time_iter': 1.7939, 'accuracy': 0.84711, 'precision': 0.79798, 'recall': 0.82292, 'f1': 0.81026, 'auc': 0.9209}
val: {'epoch': 41, 'time_epoch': 2.77233, 'loss': 0.76359778, 'lr': 0, 'params': 490650, 'time_iter': 0.55447, 'accuracy': 0.68212, 'precision': 0.89423, 'recall': 0.71538, 'f1': 0.79487, 'auc': 0.68718}
test: {'epoch': 41, 'time_epoch': 2.75581, 'loss': 0.69421565, 'lr': 0, 'params': 490650, 'time_iter': 0.55116, 'accuracy': 0.69079, 'precision': 0.90476, 'recall': 0.46914, 'f1': 0.61789, 'auc': 0.8369}
> Epoch 41: took 70.2s (avg 69.1s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 42, 'time_epoch': 64.93001, 'eta': 446.25032, 'eta_hours': 0.12396, 'loss': 0.34715158, 'lr': 0.00061847, 'params': 490650, 'time_iter': 1.80361, 'accuracy': 0.85041, 'precision': 0.80698, 'recall': 0.81875, 'f1': 0.81282, 'auc': 0.92134}
val: {'epoch': 42, 'time_epoch': 2.79428, 'loss': 0.93611315, 'lr': 0, 'params': 490650, 'time_iter': 0.55886, 'accuracy': 0.59603, 'precision': 0.91566, 'recall': 0.58462, 'f1': 0.71362, 'auc': 0.69341}
test: {'epoch': 42, 'time_epoch': 2.79769, 'loss': 0.94211009, 'lr': 0, 'params': 490650, 'time_iter': 0.55954, 'accuracy': 0.59211, 'precision': 0.82759, 'recall': 0.2963, 'f1': 0.43636, 'auc': 0.81638}
> Epoch 42: took 70.6s (avg 69.2s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 43, 'time_epoch': 66.15639, 'eta': 382.82841, 'eta_hours': 0.10634, 'loss': 0.32715922, 'lr': 0.00047586, 'params': 490650, 'time_iter': 1.83768, 'accuracy': 0.85702, 'precision': 0.80396, 'recall': 0.84583, 'f1': 0.82437, 'auc': 0.93017}
val: {'epoch': 43, 'time_epoch': 2.96904, 'loss': 0.84687765, 'lr': 0, 'params': 490650, 'time_iter': 0.59381, 'accuracy': 0.58278, 'precision': 0.90361, 'recall': 0.57692, 'f1': 0.70423, 'auc': 0.7033}
test: {'epoch': 43, 'time_epoch': 2.86446, 'loss': 0.889102, 'lr': 0, 'params': 490650, 'time_iter': 0.57289, 'accuracy': 0.61184, 'precision': 0.89286, 'recall': 0.30864, 'f1': 0.45872, 'auc': 0.81395}
> Epoch 43: took 72.1s (avg 69.2s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 44, 'time_epoch': 67.5468, 'eta': 319.43946, 'eta_hours': 0.08873, 'loss': 0.3267995, 'lr': 0.00035112, 'params': 490650, 'time_iter': 1.8763, 'accuracy': 0.86446, 'precision': 0.82114, 'recall': 0.84167, 'f1': 0.83128, 'auc': 0.93093}
val: {'epoch': 44, 'time_epoch': 3.19084, 'loss': 0.85095165, 'lr': 0, 'params': 490650, 'time_iter': 0.63817, 'accuracy': 0.62252, 'precision': 0.91954, 'recall': 0.61538, 'f1': 0.73733, 'auc': 0.71502}
test: {'epoch': 44, 'time_epoch': 3.15568, 'loss': 0.82128873, 'lr': 0, 'params': 490650, 'time_iter': 0.63114, 'accuracy': 0.64474, 'precision': 0.84615, 'recall': 0.40741, 'f1': 0.55, 'auc': 0.83325}
> Epoch 44: took 74.0s (avg 69.4s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 45, 'time_epoch': 69.42899, 'eta': 256.03341, 'eta_hours': 0.07112, 'loss': 0.3185244, 'lr': 0.00024472, 'params': 490650, 'time_iter': 1.92858, 'accuracy': 0.85868, 'precision': 0.81466, 'recall': 0.83333, 'f1': 0.82389, 'auc': 0.93367}
val: {'epoch': 45, 'time_epoch': 3.2355, 'loss': 0.85210327, 'lr': 0, 'params': 490650, 'time_iter': 0.6471, 'accuracy': 0.60927, 'precision': 0.91765, 'recall': 0.6, 'f1': 0.72558, 'auc': 0.70586}
test: {'epoch': 45, 'time_epoch': 3.21038, 'loss': 0.82925741, 'lr': 0, 'params': 490650, 'time_iter': 0.64208, 'accuracy': 0.66447, 'precision': 0.85714, 'recall': 0.44444, 'f1': 0.58537, 'auc': 0.83255}
> Epoch 45: took 76.0s (avg 69.5s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 46, 'time_epoch': 69.70409, 'eta': 192.38861, 'eta_hours': 0.05344, 'loss': 0.31085551, 'lr': 0.00015708, 'params': 490650, 'time_iter': 1.93622, 'accuracy': 0.86529, 'precision': 0.81262, 'recall': 0.85833, 'f1': 0.83485, 'auc': 0.9366}
val: {'epoch': 46, 'time_epoch': 3.25458, 'loss': 0.70526165, 'lr': 0, 'params': 490650, 'time_iter': 0.65092, 'accuracy': 0.66225, 'precision': 0.90722, 'recall': 0.67692, 'f1': 0.77533, 'auc': 0.70586}
test: {'epoch': 46, 'time_epoch': 3.20698, 'loss': 0.73812869, 'lr': 0, 'params': 490650, 'time_iter': 0.6414, 'accuracy': 0.67105, 'precision': 0.84444, 'recall': 0.46914, 'f1': 0.60317, 'auc': 0.8289}
> Epoch 46: took 76.2s (avg 69.6s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 47, 'time_epoch': 69.74636, 'eta': 128.49311, 'eta_hours': 0.03569, 'loss': 0.33411212, 'lr': 8.856e-05, 'params': 490650, 'time_iter': 1.9374, 'accuracy': 0.85455, 'precision': 0.80645, 'recall': 0.83333, 'f1': 0.81967, 'auc': 0.92686}
val: {'epoch': 47, 'time_epoch': 3.26151, 'loss': 0.80680149, 'lr': 0, 'params': 490650, 'time_iter': 0.6523, 'accuracy': 0.61589, 'precision': 0.90909, 'recall': 0.61538, 'f1': 0.73394, 'auc': 0.7033}
test: {'epoch': 47, 'time_epoch': 3.2272, 'loss': 0.80554867, 'lr': 0, 'params': 490650, 'time_iter': 0.64544, 'accuracy': 0.65132, 'precision': 0.83333, 'recall': 0.4321, 'f1': 0.56911, 'auc': 0.82925}
> Epoch 47: took 76.3s (avg 69.8s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 48, 'time_epoch': 69.96519, 'eta': 64.36326, 'eta_hours': 0.01788, 'loss': 0.30941704, 'lr': 3.943e-05, 'params': 490650, 'time_iter': 1.94348, 'accuracy': 0.87934, 'precision': 0.83534, 'recall': 0.86667, 'f1': 0.85072, 'auc': 0.93806}
val: {'epoch': 48, 'time_epoch': 3.27467, 'loss': 0.84226517, 'lr': 0, 'params': 490650, 'time_iter': 0.65493, 'accuracy': 0.60927, 'precision': 0.90805, 'recall': 0.60769, 'f1': 0.72811, 'auc': 0.69963}
test: {'epoch': 48, 'time_epoch': 3.24762, 'loss': 0.82693589, 'lr': 0, 'params': 490650, 'time_iter': 0.64952, 'accuracy': 0.63816, 'precision': 0.825, 'recall': 0.40741, 'f1': 0.54545, 'auc': 0.8289}
> Epoch 48: took 76.5s (avg 69.9s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
train: {'epoch': 49, 'time_epoch': 69.83481, 'eta': 0.0, 'eta_hours': 0.0, 'loss': 0.31348133, 'lr': 9.87e-06, 'params': 490650, 'time_iter': 1.93986, 'accuracy': 0.86364, 'precision': 0.81437, 'recall': 0.85, 'f1': 0.8318, 'auc': 0.93618}
val: {'epoch': 49, 'time_epoch': 3.28557, 'loss': 0.86084058, 'lr': 0, 'params': 490650, 'time_iter': 0.65711, 'accuracy': 0.60265, 'precision': 0.91667, 'recall': 0.59231, 'f1': 0.71963, 'auc': 0.69963}
test: {'epoch': 49, 'time_epoch': 3.24439, 'loss': 0.8420814, 'lr': 0, 'params': 490650, 'time_iter': 0.64888, 'accuracy': 0.63816, 'precision': 0.84211, 'recall': 0.39506, 'f1': 0.53782, 'auc': 0.82855}
> Epoch 49: took 76.4s (avg 70.0s) | Best so far: epoch 9	train_loss: 0.5370 train_auc: 0.8040	val_loss: 0.4877 val_auc: 0.7454	test_loss: 0.5484 test_auc: 0.8051
-----------------------------------------------------------
Avg time per epoch: 70.05s
Total train loop time: 0.97h
Task done, results saved in results/molbace-GRIT-RRWP/1
9
{'epoch': 9, 'time_epoch': 64.04504, 'eta': 2585.64781, 'eta_hours': 0.71824, 'loss': 0.53696244, 'lr': 0.00922164, 'params': 490650, 'time_iter': 1.77903, 'accuracy': 0.72645, 'precision': 0.6778, 'recall': 0.59167, 'f1': 0.63181, 'auc': 0.80401}
{'epoch': 9, 'time_epoch': 2.73685, 'loss': 0.4876915, 'lr': 0, 'params': 490650, 'time_iter': 0.54737, 'accuracy': 0.75497, 'precision': 0.89744, 'recall': 0.80769, 'f1': 0.8502, 'auc': 0.74542}
Results aggregated across runs saved in results/molbace-GRIT-RRWP/agg
[*] All done: 2025-05-11 01:31:39.127893
